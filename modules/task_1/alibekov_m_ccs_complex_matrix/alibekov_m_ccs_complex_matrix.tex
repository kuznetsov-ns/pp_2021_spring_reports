\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}


\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\lstset{language=C++,
	basicstyle=\footnotesize,
	keywordstyle=\color{blue}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	commentstyle=\color{green}\ttfamily,
	morecomment=[l][\color{magenta}]{\#}, 
	tabsize=4,
	breaklines=true,
	breakatwhitespace=true,
	title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother


\begin{document}

	\begin{titlepage}

		\begin{center}
			Министерство науки и высшего образования Российской Федерации
		\end{center}

		\begin{center}
			Федеральное государственное автономное образовательное учреждение высшего образования \\
			Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
		\end{center}

		\begin{center}
			Институт информационных технологий, математики и механики
		\end{center}

		\vspace{4em}

		\begin{center}
			\textbf{\LargeОтчет по лабораторной работе} \\
		\end{center}
		\begin{center}
			\textbf{\Large«Умножение разреженных матриц. Элементы комплексного типа. Формат хранения матрицы – столбцовый (CCS)»} \\
		\end{center}

		\vspace{4em}

		\newbox{\lbox}
		\savebox{\lbox}{\hbox{text}}
		\newlength{\maxl}
		\setlength{\maxl}{\wd\lbox}
		\hfill\parbox{7cm}{
			\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнил:} \\ студент группы 381806-1 \\ Алибеков М. Р.\\
			\\
			\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В.\\
		}
		\vspace{\fill}

		\begin{center} Нижний Новгород \\ 2021 \end{center}

	\end{titlepage}

	\setcounter{page}{2}


	% Содержание
	\tableofcontents
	\newpage


	% Введение
	\section*{Введение}
	\addcontentsline{toc}{section}{Введение}
		\par Умножение матриц - одна из наиболее популярных операций, лежащая в основе практически всех научных и инженерных областей, начиная от абстрактных задач высшей алгебры, заканчивая прикладными задачами компьютерного зрения и анализа данных. И иногда матрицы имеют структуру, в которой практичсеки 98-99\% занимают нули. Такие матрицы называют разреженными, и для них существуют специальные форматы хранения и умножения, при которых минимизируются затраты на память и время выполнения. В данной лабораторной работе рассматривается умножение комплексных матриц в столбцовом (Compressed Column Storage (CCS)) формате.
		\par Особенность CCS формата хранения в том, что сама матрица хранится не в привычном виде двумерного (зачастую одномерного) массива значений, тем самым занимая O(N * N) памяти, а в виде структуры из трех массивов: 
		\begin{itemize}
			\item values - массив значений,
			\item rows - массив номеров строк,
			\item col\_indexes - массив индексов столбцов,
		\end{itemize}
		тем самым уменьшая размер занимаемой памяти до O(NZ + NZ + N), где N - число столбцов матрицы, а NZ - число ненулевых элементов.
		\par Однако есть ещё один способ ускорить умножение, помимо использования специфического формата хранения - воспользоваться технологиями параллельного программирования, и тем самым увеличить производительность, не прибегая к реализации чрезвычайно нетривиальных алгоритмов. Примером использования технологий параллельного программирования служит данная работа, в которой реализован один из наиболее популярных форматов хранения разреженных матриц.
	\newpage


	% Постановка задачи
	\section*{Постановка задачи}
	\addcontentsline{toc}{section}{Постановка задачи}
		\par В данной работе требуется реализовать программный комплекс, позволяющий выполнять умножение разреженных комплексных матриц (формат хранения матрицы – столбцовый (CCS)) как последовательно, так и параллельно, используя технологии OpenMP (Open Multi-Processing), TBB (Intel Threading Building Blocks), std::threads.
		\par Необходимо разработать тесты для подтверждения корректности работы программы. Для их написания требуется использовать Google C++ Testing Framework.
		\par На основе разработанной программы необходимо провести оценку реализаций алгоритмов путём проведения экспериментов. Сравнив результаты экспериментов, следует сделать выводы, определить были ли параллельные реализации алгоритмов эффективней последовательной и объяснить, в силу каких причин наблюдался данный эффект.
		\par Помимо этого, в качестве дополнительного задания можно реализовать оптимизированный для данной задачи алгоритм умножения, учитывающий специфику данного формата хранения матриц. 
	\newpage


	% Описание алгоритма
	\section*{Описание алгоритмов}
	\addcontentsline{toc}{section}{Описание алгоритмов}
		\par Умножаем две комплексные разреженные CCS матрицы (для удобства назовем их A и B, а результирующую матрицу - C). Из линейной алгебры вспоминаем, что для умножения матриц неизбежно потребуется проходить по строкам первой матрицы (A) и столбцам второй (B). Из-за специфического формата хранения (CCS), проход по строкам матрицы A, очевидно, будет вычислительно гораздо затратнее, поэтому первым шагом необходимо транспонировать матрицу A. Тогда проход по строкам матрицы A будет эквивалентен проходу по столбцам транспонированной матрицы A.
		\begin{itemize}
 			\item Во внешнем цикле по столбцам транспонированной матрицы A (назовем её AT):
			\begin{itemize}
				\item Во внутреннем цикле по столбцам матрицы B:
				\begin{itemize}
					\item Находим скалярное произведение вектор-столбцов матриц B и AT:
					\begin{enumerate}[label=\alph*.]
						\item "Наивный"{} алгоритм: тривиальное сложение результатов поэлементного произведения.
						\item Оптимизированный алгоритм: ставим индексы a\_idx и b\_idx в начало, а затем проходим, "пропуская"{} нулевые элементы и умножая лишь "по необходимости"{}, т.е. если AT.rows[a\_idx] и B.rows[b\_idx] равны, то перемножаем соответствующие значения, а в противном случае - инкрементируем один из индексов (какой именно зависит от того, что больше: AT.rows[a\_idx] или B.rows[b\_idx]).
					\end{enumerate}
					\item Если скалярное произведение больше нуля, то выполняем следующие операции:
					\begin{itemize}
						\item Добавляем скалярное произведение в массив значений матрицы C.
						\item Добавляем текущий индекс (внутреннего цикла) в массив номеров строк в C.
					\end{itemize}
				\end{itemize}
				\item Добавить в конец массива индексов столбцов матрицы C значение, равное суммарному числу ненулевых элементов в текущий момент.
			\end{itemize}
		\end{itemize}
	\newpage


	% Описание схемы распараллеливания
	\section*{Описание схемы распараллеливания}
	\addcontentsline{toc}{section}{Описание схемы распараллеливания}
		\par Так как во внешнем цикле обработка каждого из столбцов матрицы AT происходит независимо от остальных, то, очевидным является распределение столбцов матрицы AT между потоками (если окажется, что число столбцов не делится на число потоков нацело, то можно остаток отдать последнему потоку).
		\par Чтобы не было проблем с доступом к массивам значений и номеров строк матрицы C, можно продублировать их по числу столбцов. После секции параллельной обработки, объединяем эти массивы. Массив индексов столбцов также нужно будет привести к нормальному состоянию, выполнив префиксную редукцию данных (алгоритм, аналогичный тому, что применяется в MPI\_Scan(...)).
	\newpage


	% Описание программной реализации
	\section*{Описание программной реализации}
	\addcontentsline{toc}{section}{Описание программной реализации}
		\par Для решения поставленных задач используется приведённый ниже основной функционал:

		\begin{itemize}
			\item Функция генерации случайной регулярной матрицы:
			\begin{lstlisting}
    ccs_complex_matrix generate_regular_ccs(int seed, 
        int N, int count_in_col);
			\end{lstlisting}
			\par На вход получает зерно для ГПСЧ (генератора псевдослучайных чисел), размеры (число всех элементов в каждом столбце) квадратной комплексной матрицы и число ненулевых элементов в каждом столобце.
			\par На выходе получаем случайно сгенерированную квадратную комплексную разреженную матрицу, представленную в CCS формате, заданных размеров и с заданным числом ненулевых элементов.

			\item Функция транспонирования матрицы:
			\begin{lstlisting}
	ccs_complex_matrix transpose(const ccs_complex_matrix &A);
			\end{lstlisting}
			\par На вход получает комплексную разреженную матрицу.
			\par На выходе получаем транспонированную матрицу.

			\item Функция, реализующая последовательную версию "наивного"{} алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix naive_multiplicate(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы. 
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая последовательную версию оптимизированного алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix optim_multiplicate(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы. 
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную OpenMP-версию "наивного"{} алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix naive_multiplicate_omp(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы.  
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную OpenMP-версию оптимизированного алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix optim_multiplicate_omp(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы.  
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную TBB-версию "наивного"{} алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix naive_multiplicate_tbb(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы. 
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную TBB-версию оптимизированного алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix optim_multiplicate_tbb(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы. 
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную std::threads-версию "наивного"{} алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix naive_multiplicate_std(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы.  
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.

			\item Функция, реализующая параллельную std::threads-версию оптимизированного алгоритма умножения:
			\begin{lstlisting}
	ccs_complex_matrix optim_multiplicate_std(const ccs_complex_matrix &A, 
        const ccs_complex_matrix &B);
			\end{lstlisting}
			\par На вход получает две комплексные разреженные CCS матрицы. 
			\par На выходе получаем комплексную разреженную матрицу - результат умножения входных матриц.
		\end{itemize}
	\newpage


	% Описание экспериментов
	\section*{Описание экспериментов}
	\addcontentsline{toc}{section}{Описание экспериментов}
		\par Умножение и замеры времени для последовательных и параллельных реализаций проводились на случайно сгенерированных "регулярных" (в каждом столбце одинаковое фиксированное количество ненулевых элементов) матрицах различного размера.
		\par Также для удобства был реализован небольшой дополнительный функционал в виде функций, позволяющих сравнивать разреженные матрицы на равенство и выводить на экран разреженные матрицы в различных форматах.
		\par Для подтверждения корректности в программе представлен набор тестов, разработанных с помощью Google C++ Testing Framework. Сам набор представляет из себя тесты, проверяющие работу функций последовательных и параллельных реализаций алгоритмов на различных матрицах.
		\par Успешное прохождение всех тестов доказывает корректность работы данной программы.
	\newpage


	% Результаты экспериментов
	\section*{Результаты экспериментов}
	\addcontentsline{toc}{section}{Результаты экспериментов}
	\par Для проведения тестов было использовано оборудование со следующими аппаратными характеристиками:
	\begin{itemize}
		\item Процессор: Intel(R) Core(TM) i5-4690K CPU @ 3.50GHz, 4 ядра;
		\item Оперативная память: 16 ГБ;
		\item ОС: Ubuntu 20.04.2 LTS.
	\end{itemize}
	\par Столбец "Макс. ускорение"{} в таблицах ниже содержит отношение времени выполнения последовательной версии "наивного"{} алгоритма к времени выполнения соответствующей версии оптимизированного алгоритма.
	\par Результаты тестов для матриц размером 2000 x 2000 (число ненулевых элементов - 2\%) представлены в Таблице 1.
	\begin{table}[!h]
		\caption{Результаты экспериментов для матриц размером 2000 x 2000 (число ненулевых элементов - 2\%)}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			Версия &
			\multicolumn{2}{|c|}{"Наивный"{} алгоритм} &
			\multicolumn{2}{|c|}{Оптим. алгоритм} &
			Макс. \\
			\cline{2-5}
			алгоритма	&  Время (с)  &  Ускорение  &   Время (с)  &  Ускорение  &  ускорение   \\
			\hline
			Последовательная	&	42.78	&	1.000	&	5.24	&	1.000	&	8.164	\\
			\hline
			OpenMP			&	12.24	&	3.495	&	1.53	&	3.425	&	27.961	\\
			\hline
			TBB				&	12.36	&	3.461	&	1.49	&	3.517	&	28.711	\\
			\hline
			std::threads		&	12.43	&	3.442	&	1.53	&	3.425	&	27.961	\\
			\hline
		\end{tabular}
	\end{table}
	\par Результаты тестов для матриц размером 3000 x 3000 (число ненулевых элементов - 2\%) представлены в Таблице 2.
	\begin{table}[!h]
		\caption{Результаты экспериментов для матриц размером 3000 x 3000 (число ненулевых элементов - 2\%)}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			Версия &
			\multicolumn{2}{|c|}{"Наивный"{} алгоритм} &
			\multicolumn{2}{|c|}{Оптим. алгоритм} &
			Макс. \\
			\cline{2-5}
			алгоритма	&  Время (с)  &  Ускорение  &   Время (с)  &  Ускорение  &  ускорение   \\
			\hline
			Последовательная	&	210.39	&	1.000	&	17.33	&	1.000	&	12.140	\\
			\hline
			OpenMP			&	59.95	&	3.509	&	5.07	&	3.418	&	41.497	\\
			\hline
			TBB				&	59.67	&	3.526	&	4.97	&	3.487	&	42.332	\\
			\hline
			std::threads		&	60.92	&	3.454	&	5.06	&	3.425	&	41.579	\\
			\hline
		\end{tabular}
	\end{table}
	\par Результаты тестов для матриц размером 3000 x 3000 (число ненулевых элементов - 0.5\%) представлены в Таблице 3.
	\begin{table}[!h]
		\caption{Результаты экспериментов для матриц размером 3000 x 3000 (число ненулевых элементов - 0.5\%)}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			Версия &
			\multicolumn{2}{|c|}{"Наивный"{} алгоритм} &
			\multicolumn{2}{|c|}{Оптим. алгоритм} &
			Макс. \\
			\cline{2-5}
			алгоритма	&  Время (с)  &  Ускорение  &   Время (с)  &  Ускорение  &  ускорение   \\
			\hline
			Последовательная	&	15.02	&	1.000	&	3.98	&	1.000	&	3.774	\\
			\hline
			OpenMP			&	4.40	&	3.414	&	1.17	&	3.402	&	12.838	\\
			\hline
			TBB				&	4.33	&	3.469	&	1.11	&	3.586	&	13.532	\\
			\hline
			std::threads		&	4.31	&	3.485	&	1.15	&	3.461	&	13.061	\\
			\hline
		\end{tabular}
	\end{table}
	\par По результатам тестов, можно сделать следующие выводы:
	\begin{itemize}
		\item Оптимизированный алгоритм в разы быстрее "наивной"{}, поэтому алгоритмическая оптимизация не была напрасной.
		\item Все параллельные реализации (OpenMP, TBB, std::threads) действительно работают быстрее, чем последовательные, причем ускорение весьма значительное (в 3.5 раза)!
		\item Несмотря на то, что ускорение у всех параллельных версий приблизительно одинаковое, как правило, TBB версия немного быстрее остальных (особенно для оптимизированного алгоритма).
		\item Величина ускорения не зависит от размеров матрицы, числа ненулевых элементов и используемого алгоритма.
		\item Время выполнения прямо пропорционально размерам матрицы.
		\item Время выполнения прямо пропорционально числу ненулевых элементов в матрице.
	\end{itemize}
	\par Причиной такого относительно большого ускорения является независимость обработки каждого столбца матрицы от остальных, т.е. отсутствие зависимостей между отдельными итерациями в цикле. И, как видно из тестов, ускорение стабильное, т.е. спада эффективности (уменьшения величины ускорения) при увеличении размеров матрицы не наблюдается, поэтому можно сделать вывод, что оптимизация была весьма успешной.
	\newpage


	% Заключение
	\section*{Заключение}
	\addcontentsline{toc}{section}{Заключение}
		\par В результате лабораторной работы был разработан программный комплекс, позволяющий выполнять умножение разреженных матриц с элементами комплексного типа с замерами времени выполнения. Формат хранения матрицы – столбцовый (CCS). Показана эффективность параллельных версий. А также реализованы и пройдены тесты, проверяющие корректность работы функций.
		\par Таким образом, все цели, поставленные в данной лабораторной работе, были успешно достигнуты.
	\newpage


	% Список литературы
	\begin{thebibliography}{1}
	\addcontentsline{toc}{section}{Список литературы}
		\bibitem{cppreference} cppreference [Электронный ресурс] // https://en.cppreference.com/w/ (дата обращения: 02.05.2021)
        \bibitem{TBB} Intel® Threading Building Blocks Documentation [Электронный ресурс] // URL: https://software.intel.com/en-us/tbb-documentation (дата обращения: 02.05.2021)
		\bibitem{PP} К.В. Корняков, В.Д. Кустикова, И.Б. Мееров, А.А. Сиднев, А.В.Сысоев, А.В. Шишков. Инструменты паралельного программирования в системах с общей памятью //Москва: Изд-во МГУ. – 2010, 272 с.
	\end{thebibliography}
	\newpage


	% Приложение
	\section*{Приложение}
	\addcontentsline{toc}{section}{Приложение}
	\par В текущем разделе находится листинг кода, написанного в рамках данной лабораторной работы.
	\begin{lstlisting}
		// ccs_complex_matrix.h
		
// Copyright 2021 Alibekov Murad
#ifndef MODULES_TASK_4_ALIBEKOV_M_CCS_COMPLEX_MATRIX_CCS_COMPLEX_MATRIX_H_
#define MODULES_TASK_4_ALIBEKOV_M_CCS_COMPLEX_MATRIX_CCS_COMPLEX_MATRIX_H_

#include <omp.h>

#include <tbb/parallel_for.h>
#include <tbb/blocked_range.h>
#include <tbb/tick_count.h>

#include <vector>
#include <complex>
#include <iostream>
#include <utility>
#include <random>

#include "../../../3rdparty/unapproved/unapproved.h"

const double ZERO_IN_CCS = 0.00001;

struct ccs_complex_matrix {
    int N;       // size of matrix (N x N)
    int NZ;      // count of non-zero elements

    // array of values (size = NZ):
    std::vector<std::complex<double> > values;

    // array of rows' numbers (size = NZ):
    std::vector<int> rows;

    // array of columns' indexes (size = N + 1):
    std::vector<int> col_indexes;

    ccs_complex_matrix(int _N, int _NZ) {
        N = _N;
        NZ = _NZ;
        values = std::vector<std::complex<double> >(NZ);
        rows = std::vector<int>(NZ);
        col_indexes = std::vector<int>(N + 1);
    }

    friend bool operator==(const ccs_complex_matrix &A, const ccs_complex_matrix &B);
};

ccs_complex_matrix generate_regular_ccs(int seed, int N, int count_in_col);

ccs_complex_matrix transpose(const ccs_complex_matrix &A);
ccs_complex_matrix naive_multiplicate(const ccs_complex_matrix &A, const ccs_complex_matrix &B);
ccs_complex_matrix optim_multiplicate(const ccs_complex_matrix &A, const ccs_complex_matrix &B);

ccs_complex_matrix naive_multiplicate_omp(const ccs_complex_matrix &A, const ccs_complex_matrix &B);
ccs_complex_matrix optim_multiplicate_omp(const ccs_complex_matrix &A, const ccs_complex_matrix &B);

ccs_complex_matrix naive_multiplicate_tbb(const ccs_complex_matrix &A,
        const ccs_complex_matrix &B,
        int _gransize = 1);
ccs_complex_matrix optim_multiplicate_tbb(const ccs_complex_matrix &A,
        const ccs_complex_matrix &B,
        int _gransize = 1);

ccs_complex_matrix naive_multiplicate_std(const ccs_complex_matrix &A, const ccs_complex_matrix &B);
ccs_complex_matrix optim_multiplicate_std(const ccs_complex_matrix &A, const ccs_complex_matrix &B);

void PrintCCSMatrix(const ccs_complex_matrix &A, bool isComplex = true);
void PrintDensificationOfCCSMatrix(const ccs_complex_matrix &A, bool isComplex = true);

bool operator==(const ccs_complex_matrix &A, const ccs_complex_matrix &B);

#endif  // MODULES_TASK_4_ALIBEKOV_M_CCS_COMPLEX_MATRIX_CCS_COMPLEX_MATRIX_H_
	\end{lstlisting}
	\begin{lstlisting}
		// ccs_complex_matrix.cpp

// Copyright 2021 Alibekov Murad
#include "../../../modules/task_4/alibekov_m_ccs_complex_matrix/ccs_complex_matrix.h"

ccs_complex_matrix generate_regular_ccs(int seed, int N, int count_in_col) {
    if ((N <= 0) || (count_in_col <= 0))
        throw -1;

    std::mt19937 gen;
    gen.seed(static_cast<unsigned int>(seed));

    ccs_complex_matrix random_matrix(N, count_in_col * N);

    for (int i = 0; i < N; i++) {
        for (int j = i * count_in_col; j < (i + 1) * count_in_col; j++) {
            bool isFound = false;
            do {
                random_matrix.rows[j] = static_cast<unsigned int>(gen()) % N;
                isFound = true;
                for (int k = i * count_in_col; k < j; k++) {
                    if (random_matrix.rows[j] == random_matrix.rows[k])
                        isFound = false;
                    }
            } while (!isFound);
        }

        // BubbleSort
        for (int j = 0; j < count_in_col - 1; j++)
            for (int k = i * count_in_col; k < (i + 1) * count_in_col - 1 - j; k++)
                if (random_matrix.rows[k] > random_matrix.rows[k + 1])
                    std::swap(random_matrix.rows[k], random_matrix.rows[k + 1]);
    }

    std::random_device rd;
    std::mt19937 mersenne(rd());
    std::uniform_real_distribution<> rnd(-30, 30);

    for (int i = 0; i < count_in_col * N; i++)
        random_matrix.values[i] = { rnd(mersenne), rnd(mersenne) };

    for (int i = 0; i < N + 1; i++)
        random_matrix.col_indexes[i] = i * count_in_col;

    return random_matrix;
}

ccs_complex_matrix transpose(const ccs_complex_matrix &A) {
    ccs_complex_matrix AT(A.N, A.NZ);

    for (int i = 0; i < A.NZ; i++)
        AT.col_indexes[A.rows[i] + 1]++;

    int S = 0;
    for (int i = 1; i <= A.N; i++) {
        int tmp = AT.col_indexes[i];
        AT.col_indexes[i] = S;
        S = S + tmp;
    }

    for (int i = 0; i < A.N; i++) {
        int row = i;
        for (int j = A.col_indexes[i]; j < A.col_indexes[i + 1]; j++) {
            std::complex<double> AT_V = A.values[j];
            int AT_col_index = A.rows[j];
            int AT_j_index = AT.col_indexes[AT_col_index + 1];
            AT.values[AT_j_index] = AT_V;
            AT.rows[AT_j_index] = row;
            AT.col_indexes[AT_col_index + 1]++;
        }
    }

    return AT;
}

ccs_complex_matrix naive_multiplicate(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    int rows_count = 0;
    std::vector<int> rows;
    std::vector<std::complex<double> > values;
    std::vector<int> col_indexes;

    col_indexes.push_back(0);
    for (int i = 0; i < N; i++) {
        int count_NZ = 0;
        for (int j = 0; j < N; j++) {
            std::complex<double> sum = {0, 0};

            // dot_product
            for (int k = AT.col_indexes[j]; k < AT.col_indexes[j + 1]; k++)
                for (int l = B.col_indexes[i]; l < B.col_indexes[i + 1]; l++)
                    if (AT.rows[k] == B.rows[l]) {
                        sum += AT.values[k] * B.values[l];
                        break;
                    }

            if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                rows.push_back(j);
                rows_count++;
                values.push_back(sum);
                count_NZ++;
            }
        }
        col_indexes.push_back(count_NZ + col_indexes[i]);
    }

    ccs_complex_matrix C(N, rows_count);
    for (int j = 0; j < rows_count; j++) {
        C.rows[j] = rows[j];
        C.values[j] = values[j];
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix optim_multiplicate(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    std::vector<int> rows;
    std::vector<std::complex<double> > values;
    std::vector<int> col_indexes;

    col_indexes.push_back(0);
    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            std::complex<double> sum = {0, 0};

            // like merging 2 sorted arrays
            int a_idx = AT.col_indexes[j];
            int b_idx = B.col_indexes[i];
            while ((a_idx < AT.col_indexes[j + 1]) && (b_idx < B.col_indexes[i + 1])) {
                if (AT.rows[a_idx] < B.rows[b_idx]) {
                    a_idx++;
                } else {
                    if (AT.rows[a_idx] > B.rows[b_idx])
                        b_idx++;
                    else
                        sum += AT.values[a_idx++] * B.values[b_idx++];
                }
            }

            if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                rows.push_back(j);
                values.push_back(sum);
                count_NZ++;
            }
        }
        col_indexes.push_back(count_NZ);
    }

    ccs_complex_matrix C(N, count_NZ);

    for (int j = 0; j < count_NZ; j++) {
        C.rows[j] = rows[j];
        C.values[j] = values[j];
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix naive_multiplicate_omp(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            std::complex<double> sum = {0, 0};

            // dot_product
            for (int k = AT.col_indexes[j]; k < AT.col_indexes[j + 1]; k++)
                for (int l = B.col_indexes[i]; l < B.col_indexes[i + 1]; l++)
                    if (AT.rows[k] == B.rows[l]) {
                        sum += AT.values[k] * B.values[l];
                        break;
                    }

            if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                rows[i].push_back(j);
                values[i].push_back(sum);
                col_indexes[i]++;
            }
        }
    }

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix optim_multiplicate_omp(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    #pragma omp parallel for
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            std::complex<double> sum = {0, 0};

            // like merging 2 sorted arrays
            int a_idx = AT.col_indexes[j];
            int b_idx = B.col_indexes[i];
            while ((a_idx < AT.col_indexes[j + 1]) && (b_idx < B.col_indexes[i + 1])) {
                if (AT.rows[a_idx] < B.rows[b_idx]) {
                    a_idx++;
                } else {
                    if (AT.rows[a_idx] > B.rows[b_idx])
                        b_idx++;
                    else
                        sum += AT.values[a_idx++] * B.values[b_idx++];
                }
            }

            if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                rows[i].push_back(j);
                values[i].push_back(sum);
                col_indexes[i]++;
            }
        }
    }

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix naive_multiplicate_tbb(const ccs_complex_matrix &A,
        const ccs_complex_matrix &B,
        int _gransize) {
    ccs_complex_matrix AT = transpose(A);

    if (A.N != B.N)
        throw -1;
    if (_gransize < 0)
        throw -1;

    int N = A.N;
    int gransize = _gransize;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    tbb::parallel_for(tbb::blocked_range<int>(0, N, gransize),
        [&](const tbb::blocked_range<int> &r) {
            int begin = r.begin();
            int end = r.end();
            for (int i = begin; i < end; i++) {
                for (int j = 0; j < N; j++) {
                    std::complex<double> sum = {0, 0};

                    // dot_product
                    for (int k = AT.col_indexes[j]; k < AT.col_indexes[j + 1]; k++)
                        for (int l = B.col_indexes[i]; l < B.col_indexes[i + 1]; l++)
                            if (AT.rows[k] == B.rows[l]) {
                                sum += AT.values[k] * B.values[l];
                                break;
                            }

                    if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                        rows[i].push_back(j);
                        values[i].push_back(sum);
                        col_indexes[i]++;
                    }
                }
            }
        });

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix optim_multiplicate_tbb(const ccs_complex_matrix &A,
        const ccs_complex_matrix &B,
        int _gransize) {
    ccs_complex_matrix AT = transpose(A);

    if (A.N != B.N)
        throw -1;
    if (_gransize < 0)
        throw -1;

    int N = A.N;
    int gransize = _gransize;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    tbb::parallel_for(tbb::blocked_range<int>(0, N, gransize),
        [&](const tbb::blocked_range<int> &r) {
            int begin = r.begin();
            int end = r.end();
            for (int i = begin; i < end; i++) {
                for (int j = 0; j < N; j++) {
                    std::complex<double> sum = {0, 0};

                    // like merging 2 sorted arrays
                    int a_idx = AT.col_indexes[j];
                    int b_idx = B.col_indexes[i];
                    while ((a_idx < AT.col_indexes[j + 1]) && (b_idx < B.col_indexes[i + 1])) {
                        if (AT.rows[a_idx] < B.rows[b_idx]) {
                            a_idx++;
                        } else {
                            if (AT.rows[a_idx] > B.rows[b_idx])
                                b_idx++;
                            else
                                sum += AT.values[a_idx++] * B.values[b_idx++];
                        }
                    }

                    if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                        rows[i].push_back(j);
                        values[i].push_back(sum);
                        col_indexes[i]++;
                    }
                }
            }
        });

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix naive_multiplicate_std(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    int threads_count = static_cast<int>(std::thread::hardware_concurrency());
    std::vector<std::thread> threads_pool;

    auto thread_partial_calculation =
        [&](int begin, int end) {
            for (int i = begin; i < end; i++) {
                for (int j = 0; j < N; j++) {
                    std::complex<double> sum = {0, 0};

                    // dot_product
                    for (int k = AT.col_indexes[j]; k < AT.col_indexes[j + 1]; k++)
                        for (int l = B.col_indexes[i]; l < B.col_indexes[i + 1]; l++)
                            if (AT.rows[k] == B.rows[l]) {
                                sum += AT.values[k] * B.values[l];
                                break;
                            }

                    if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                        rows[i].push_back(j);
                        values[i].push_back(sum);
                        col_indexes[i]++;
                    }
                }
            }
        };

    int delta = N / threads_count;
    if (delta > 0) {
        for (int thread_id = 0; thread_id < threads_count - 1; thread_id++) {
            int left_border_value = thread_id * delta;
            threads_pool.emplace_back(std::thread(
                thread_partial_calculation, left_border_value, left_border_value + delta));
        }
    }
    threads_pool.emplace_back(std::thread(
        thread_partial_calculation, (threads_count - 1) * delta, N));

    for (std::thread &thread : threads_pool) {
        thread.join();
    }

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

ccs_complex_matrix optim_multiplicate_std(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    ccs_complex_matrix AT = transpose(A);
    if (A.N != B.N)
        throw -1;

    int N = A.N;

    std::vector<std::vector<int> > rows(N);
    std::vector<std::vector<std::complex<double> > > values(N);
    std::vector<int> col_indexes(N + 1);

    int threads_count = static_cast<int>(std::thread::hardware_concurrency());
    std::vector<std::thread> threads_pool;

    auto thread_partial_calculation =
        [&](int begin, int end) {
            for (int i = begin; i < end; i++) {
                for (int j = 0; j < N; j++) {
                    std::complex<double> sum = {0, 0};

                    // like merging 2 sorted arrays
                    int a_idx = AT.col_indexes[j];
                    int b_idx = B.col_indexes[i];
                    while ((a_idx < AT.col_indexes[j + 1]) && (b_idx < B.col_indexes[i + 1])) {
                        if (AT.rows[a_idx] < B.rows[b_idx]) {
                            a_idx++;
                        } else {
                            if (AT.rows[a_idx] > B.rows[b_idx])
                                b_idx++;
                            else
                                sum += AT.values[a_idx++] * B.values[b_idx++];
                        }
                    }

                    if ((fabs(sum.real()) > ZERO_IN_CCS) || (fabs(sum.imag()) > ZERO_IN_CCS)) {
                        rows[i].push_back(j);
                        values[i].push_back(sum);
                        col_indexes[i]++;
                    }
                }
            }
        };

    int delta = N / threads_count;
    for (int thread_id = 0; thread_id < threads_count - 1; thread_id++) {
        int left_border_value = thread_id * delta;
        threads_pool.emplace_back(std::thread(
            thread_partial_calculation, left_border_value, left_border_value + delta));
    }
    threads_pool.emplace_back(std::thread(
        thread_partial_calculation, (threads_count - 1) * delta, N));

    for (std::thread &thread : threads_pool) {
        thread.join();
    }

    int count_NZ = 0;
    for (int i = 0; i < N; i++) {
        int tmp = col_indexes[i];
        col_indexes[i] = count_NZ;
        count_NZ += tmp;
    }
    col_indexes[N] = count_NZ;

    ccs_complex_matrix C(N, count_NZ);
    int count = 0;
    for (int i = 0; i < N; i++) {
        int size = rows[i].size();
        for (int j = 0; j < size; j++) {
            C.rows[count] = rows[i][j];
            C.values[count] = values[i][j];
            count++;
        }
    }

    for (int i = 0; i < N + 1; i++)
        C.col_indexes[i] = col_indexes[i];

    return C;
}

void PrintCCSMatrix(const ccs_complex_matrix &A, bool isComplex) {
    std::cout << "Matrix [" << &A << "] : \n\tvalues: [ ";
    for (int i = 0; i < A.NZ; i++)
        isComplex ? std::cout << A.values[i] << " " : std::cout << A.values[i].real() << " ";
    std::cout << "]\n\trows: [ ";
    for (int i = 0; i < A.NZ; i++)
        std::cout << A.rows[i] << " ";
    std::cout << "]\n\tcol_indexes: [ ";
    for (int i = 0; i < A.N + 1; i++)
        std::cout << A.col_indexes[i] << " ";
    std::cout << "]\n";
}

void PrintDensificationOfCCSMatrix(const ccs_complex_matrix &A, bool isComplex) {
    int N = A.N;
    std::vector<std::vector<std::complex<double> > > dense_matrix(N);
    for (int i = 0; i < N; i++)
        dense_matrix[i] = std::vector<std::complex<double> >(N);
    for (int i = 0; i < N; i++)
        for (int j = A.col_indexes[i]; j < A.col_indexes[i + 1]; j++)
            dense_matrix[A.rows[j]][i] = A.values[j];
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            isComplex ? std::cout << dense_matrix[i][j] << " " :
                std::cout << dense_matrix[i][j].real() << " ";
        }
        std::cout << std::endl;
    }
}

bool operator==(const ccs_complex_matrix &A, const ccs_complex_matrix &B) {
    return ((A.N == B.N) && (A.NZ == B.NZ) && (A.rows == B.rows)
        && (A.values == B.values) && (A.col_indexes == B.col_indexes));
}
	\end{lstlisting}
	\begin{lstlisting}
	// main.cpp

// Copyright 2021 Alibekov Murad
#include <gtest/gtest.h>
#include <vector>
#include <complex>
#include <iostream>
#include <ctime>
#include "./ccs_complex_matrix.h"

int SEED_1 = 86538;
int SEED_2 = 2395;
int N = 4500;
int COUNT_IN_COL = 90;
int TBB_GRANSIZE = N / 4500;


TEST(SPARSE_MATRICES, PRINT_SPARSE_MATRIX) {
    ccs_complex_matrix sparse_matrix(4, 6);
    sparse_matrix.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix.col_indexes = { 0, 1, 2, 4, 6 };

    std::cout << "\tFirst type:\n";
    PrintCCSMatrix(sparse_matrix);
    std::cout << std::endl;

    std::cout << "\tSecond type:\n";
    PrintCCSMatrix(sparse_matrix, false);
    std::cout << std::endl;

    std::cout << "\tThird type:\n";
    PrintDensificationOfCCSMatrix(sparse_matrix);
    std::cout << std::endl;

    std::cout << "\tFourth type:\n";
    PrintDensificationOfCCSMatrix(sparse_matrix, false);
    std::cout << std::endl;
}

TEST(SPARSE_MATRICES, THROWS_WHEN_N_IS_NEGATIVE) {
    ASSERT_ANY_THROW(generate_regular_ccs(10728, -100, 3));
}

TEST(SPARSE_MATRICES, THROWS_WHEN_N_IS_ZERO) {
    ASSERT_ANY_THROW(generate_regular_ccs(10728, 0, 3));
}

TEST(SPARSE_MATRICES, TEST_EQUAL_MATRICES) {
    ccs_complex_matrix sparse_matrix(4, 6);
    sparse_matrix.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_2(4, 6);
    sparse_matrix_2.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_2.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 4, 6 };
    
    ASSERT_TRUE(sparse_matrix_2 == sparse_matrix);
}

TEST(SPARSE_MATRICES, TEST_TRANSPOSED_SPARSE_MATRIX) {
    ccs_complex_matrix sparse_matrix(4, 6);
    sparse_matrix.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_T(4, 6);
    sparse_matrix_T.values = { 3, 7, 8, 9, 15, 16 };
    sparse_matrix_T.rows = { 1, 3, 2, 0, 2, 3 };
    sparse_matrix_T.col_indexes = { 0, 2, 3, 3, 6 };
    
    EXPECT_EQ(sparse_matrix_T, transpose(sparse_matrix));
}

TEST(SPARSE_MATRICES, TEST_DOUBLE_TRANSPOSED_SPARSE_MATRIX) {
    ccs_complex_matrix sparse_matrix(4, 6);
    sparse_matrix.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix.col_indexes = { 0, 1, 2, 4, 6 };

    EXPECT_EQ(sparse_matrix, transpose(transpose(sparse_matrix)));
}


/////////////////////////////////////////////
///    NAIVE_MULTIPLY_SPARSE_MATRICES    ////
/////////////////////////////////////////////

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };
    
    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };
    
    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };
    
    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };
    
    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };
    
    ASSERT_ANY_THROW(naive_multiplicate(sparse_matrix_1, sparse_matrix_2));
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_2(4, 0);
    
    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(naive_multiplicate(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };
    
    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};
    
    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    EXPECT_EQ(naive_multiplicate(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    double start_time = omp_get_wtime();
    EXPECT_NO_THROW(naive_multiplicate(big_sparse_matrix_1, big_sparse_matrix_2));
    double finish_time = omp_get_wtime();

    printf("\tTime  = %f\n", finish_time - start_time);
}


/////////////////////////////////////////////
///    OPTIM_MULTIPLY_SPARSE_MATRICES    ////
/////////////////////////////////////////////

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };
    
    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };
    
    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };
    
    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };
    
    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };
    
    ASSERT_ANY_THROW(optim_multiplicate(sparse_matrix_1, sparse_matrix_2));
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };
    
    ccs_complex_matrix sparse_matrix_2(4, 0);
    
    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(optim_multiplicate(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };
    
    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};
    
    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    
    EXPECT_EQ(optim_multiplicate(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    double start_time = omp_get_wtime();
    EXPECT_NO_THROW(optim_multiplicate(big_sparse_matrix_1, big_sparse_matrix_2));
    double finish_time = omp_get_wtime();

    printf("\tTime  = %f\n", finish_time - start_time);
}


/////////////////////////////////////////////////
///    NAIVE_MULTIPLY_SPARSE_MATRICES_OMP    ////
/////////////////////////////////////////////////

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_omp(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_omp(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(naive_multiplicate_omp(sparse_matrix_1, sparse_matrix_2));
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(naive_multiplicate_omp(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    EXPECT_EQ(naive_multiplicate_omp(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_OMP, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    double start_time = omp_get_wtime();
    EXPECT_NO_THROW(naive_multiplicate_omp(big_sparse_matrix_1, big_sparse_matrix_2));
    double finish_time = omp_get_wtime();

    printf("\tTime  = %f\n", finish_time - start_time);
}


/////////////////////////////////////////////////
///    OPTIM_MULTIPLY_SPARSE_MATRICES_OMP    ////
/////////////////////////////////////////////////

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_omp(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_omp(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(optim_multiplicate_omp(sparse_matrix_1, sparse_matrix_2));
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(optim_multiplicate_omp(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};

    EXPECT_EQ(optim_multiplicate_omp(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_OMP, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    double start_time = omp_get_wtime();
    EXPECT_NO_THROW(optim_multiplicate_omp(big_sparse_matrix_1, big_sparse_matrix_2));
    double finish_time = omp_get_wtime();

    printf("\tTime  = %f\n", finish_time - start_time);
}


/////////////////////////////////////////////////
///    NAIVE_MULTIPLY_SPARSE_MATRICES_TBB    ////
/////////////////////////////////////////////////

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_tbb(number_1, number_2, TBB_GRANSIZE), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_tbb(number_1, number_2, TBB_GRANSIZE), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(naive_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE));
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(naive_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    EXPECT_EQ(naive_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, THROWS_WHEN_MULTIPLY_WITH_GRANSIZE_LESS_THAN_ZERO) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    ASSERT_ANY_THROW(naive_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, -1));
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_TBB, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    tbb::tick_count start_time, finish_time;
    start_time = tbb::tick_count::now();
    EXPECT_NO_THROW(naive_multiplicate_tbb(big_sparse_matrix_1, big_sparse_matrix_2, TBB_GRANSIZE));
    finish_time = tbb::tick_count::now();

    printf("\tTime  = %f\n", (finish_time - start_time).seconds());
}


/////////////////////////////////////////////////
///    OPTIM_MULTIPLY_SPARSE_MATRICES_TBB    ////
/////////////////////////////////////////////////

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_tbb(number_1, number_2, TBB_GRANSIZE), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_tbb(number_1, number_2, TBB_GRANSIZE), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(optim_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE));
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(optim_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};

    EXPECT_EQ(optim_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, TBB_GRANSIZE), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, THROWS_WHEN_MULTIPLY_WITH_GRANSIZE_LESS_THAN_ZERO) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};
    ASSERT_ANY_THROW(optim_multiplicate_tbb(sparse_matrix_1, sparse_matrix_2, -1));
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_TBB, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    tbb::tick_count start_time, finish_time;
    start_time = tbb::tick_count::now();
    EXPECT_NO_THROW(optim_multiplicate_tbb(big_sparse_matrix_1, big_sparse_matrix_2, TBB_GRANSIZE));
    finish_time = tbb::tick_count::now();

    printf("\tTime  = %f\n", (finish_time - start_time).seconds());
}


/////////////////////////////////////////////////
///    NAIVE_MULTIPLY_SPARSE_MATRICES_STD    ////
/////////////////////////////////////////////////

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_std(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(naive_multiplicate_std(number_1, number_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(naive_multiplicate_std(sparse_matrix_1, sparse_matrix_2));
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(naive_multiplicate_std(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};

    EXPECT_EQ(naive_multiplicate_std(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(NAIVE_MULTIPLY_SPARSE_MATRICES_STD, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    auto start_time = std::chrono::high_resolution_clock::now();
    EXPECT_NO_THROW(naive_multiplicate_std(big_sparse_matrix_1, big_sparse_matrix_2));
    auto finish_time = std::chrono::high_resolution_clock::now();

    printf("\tTime  = %f\n", static_cast<float>(
        std::chrono::duration_cast<std::chrono::milliseconds>
            (finish_time - start_time).count() / 1000.));
}


/////////////////////////////////////////////////
///    OPTIM_MULTIPLY_SPARSE_MATRICES_STD    ////
/////////////////////////////////////////////////

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { 6 };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { 7 };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { 42 };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_std(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_COMPLEX_NUMBERS) {
    ccs_complex_matrix number_1(1, 1);
    number_1.values = { {-1, 2} };
    number_1.rows = { 0 };
    number_1.col_indexes = { 0, 1 };

    ccs_complex_matrix number_2(1, 1);
    number_2.values = { {3, 4} };
    number_2.rows = { 0 };
    number_2.col_indexes = { 0, 1 };

    ccs_complex_matrix result(1, 1);
    result.values = { {-11, 2} };
    result.rows = { 0 };
    result.col_indexes = { 0, 1 };

    EXPECT_EQ(optim_multiplicate_std(number_1, number_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, THROWS_WHEN_MULTIPLY_WITH_DIFFERENT_N) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { 9, 3, 8, 15, 7, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { 1, 3, 7 };
    sparse_matrix_2.rows = { 2, 2, 1 };
    sparse_matrix_2.col_indexes = { 0, 1, 2, 3 };

    ASSERT_ANY_THROW(optim_multiplicate_std(sparse_matrix_1, sparse_matrix_2));
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_SPARSE_MATRIX_AND_ZERO_MATRIX) {
    ccs_complex_matrix sparse_matrix_1(4, 6);
    sparse_matrix_1.values = { {7, 1}, {6, 4}, 2.978, {11.02, -0.9}, {-9.3, 0}, 16 };
    sparse_matrix_1.rows = { 3, 0, 1, 3, 0, 3 };
    sparse_matrix_1.col_indexes = { 0, 1, 2, 4, 6 };

    ccs_complex_matrix sparse_matrix_2(4, 0);

    ccs_complex_matrix result(4, 0);

    EXPECT_EQ(optim_multiplicate_std(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, MULTIPLY_SPARSE_MATRICES) {
    ccs_complex_matrix sparse_matrix_1(3, 4);
    sparse_matrix_1.values = { {-1, 1}, {0, 3}, 3, 0.7 };
    sparse_matrix_1.rows = { 2, 0, 2, 1 };
    sparse_matrix_1.col_indexes = { 0, 1, 3, 4 };

    ccs_complex_matrix sparse_matrix_2(3, 3);
    sparse_matrix_2.values = { {0, -3}, {0, 1}, 4 };
    sparse_matrix_2.rows = { 1, 0, 2 };
    sparse_matrix_2.col_indexes = { 0, 0, 1, 3};

    ccs_complex_matrix result(3, 4);
    result.values = { 9, {0, -9}, 2.8, {-1, -1} };
    result.rows = { 0, 2, 1, 2 };
    result.col_indexes = { 0, 0, 2, 4};

    EXPECT_EQ(optim_multiplicate_std(sparse_matrix_1, sparse_matrix_2), result);
}

TEST(OPTIM_MULTIPLY_SPARSE_MATRICES_STD, PERFORMANCE_MEASUREMENT_OF_MULTIPLICATION_BIG_SPARSE_MATRICES) {
    ccs_complex_matrix big_sparse_matrix_1 = generate_regular_ccs(SEED_1, N, COUNT_IN_COL);
    std::cout << "\tFirst matrix is generated!\n";

    ccs_complex_matrix big_sparse_matrix_2 = generate_regular_ccs(SEED_2, N, COUNT_IN_COL);
    std::cout << "\tSecond matrix is generated!\n";

    auto start_time = std::chrono::high_resolution_clock::now();
    EXPECT_NO_THROW(optim_multiplicate_std(big_sparse_matrix_1, big_sparse_matrix_2));
    auto finish_time = std::chrono::high_resolution_clock::now();

    printf("\tTime  = %f\n", static_cast<float>(
        std::chrono::duration_cast<std::chrono::milliseconds>
            (finish_time - start_time).count() / 1000.));
}


int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
	\end{lstlisting}

\end{document}