\documentclass{article}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{amsmath}

\geometry{a4paper,top=2cm,bottom=2cm,left=2.5cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\usepackage{xcolor}
\definecolor{weborange}{RGB}{255,165,0}
\definecolor{codepurple}{RGB}{220,20,60}
\definecolor{codecyan}{RGB}{135,0,198}
\definecolor{codeblue}{RGB}{69,97,189}
\definecolor{backcolour}{RGB}{230,230,220}

\usepackage{listings}
\lstset{language=C++,
	basicstyle=\ttfamily\footnotesize,
	backgroundcolor=\color{backcolour},
    	emph={int, double, time_t, char, new},
    	emphstyle={\color{blue}},
    	commentstyle=\color{green!60!black},
 	keywordstyle={\color{codepurple}},
 	keywords=[2]{std},
    	keywordstyle=[2]{\color{weborange}},
    	otherkeywords = {:},
	morekeywords = [2]{:},
   	stringstyle=\color{codepurple},
	morecomment=[l][\color{codecyan}]{\#}, 
	tabsize=2,
	breaklines=true,                               
  	breakatwhitespace=true,
  	title=\lstname,  
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large«Умножение матриц методом Фокса»} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнила:} \\ студентка группы 381806-2 \\ Груздева Д.М.\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А.В.\\
}
\vspace{\fill}

\begin{center} Нижний Новгород \\ 2021 \end{center}

\end{titlepage}

\setcounter{page}{2}

% Содержание
\tableofcontents
\newpage

% Введение
\section*{Введение}
\addcontentsline{toc}{section}{1. Введение}
\setcounter{section}{1}
\par 
Умножение матриц является базовой операцией в линейной алгебре и имеет множество применений в других областях, таких как
статистика, физика, экономика и т.д. Однако она очень затратна - последовательная версия имеет алгоритмическую сложность 
$\mathcal{O}(n^3)$, что довольно ресурсозатратно. В данной лабораторной работе мы реализуем алгоритм, уменьшающий сложность умножения
путем разделения данных между потоками - алгоритм Фокса. 
\newpage

% Постановка задачи
\section*{Постановка задачи}
\addcontentsline{toc}{section}{2. Постановка задачи}
\par 
В данном лабораторной работе требуется рассмотреть умножение матриц методом Фокса, реализовать последовательную
и две параллельные версии этого метода (при помощи технологий OpenMP и TBB), провести эксперименты для оценки времени выполнения. 
Проанализировать полученные результаты, объяснить их.
\newpage

% Описание алгоритма
\section*{Описание алгоритма}
\addcontentsline{toc}{section}{3. Описание алгоритма}
\par
Рассмотрим определение умножения матриц.
\par
Пусть даны две квадратные матрицы A и B с размерами \(n \times n\).
\[ 
	A = \left( 
		\begin{matrix}
			a_{00} & a_{0 1} & \ldots & a_{0(n-1)}\\
			a_{10} & a_{1 1} & \ldots & a_{1(n-1)}\\
			\vdots & \vdots & \ddots & \vdots\\
			a_{(n-1)0} & a_{(n-1)1} & \ldots & a_{(n-1)(n-1)}\\
		\end{matrix}
	\right)
\]
\[
	B = \left( 
		\begin{matrix}
			b_{00} & b_{0 1} & \ldots & b_{0(n-1)}\\
			b_{10} & b_{1 1} & \ldots & b_{1(n-1)}\\
			\vdots & \vdots & \ddots & \vdots\\
			b_{(n-1)0} & b_{(n-1)1} & \ldots & b_{(n-1)(n-1)}\\
		\end{matrix}
	\right)
\]

Тогда:

\par
\[C=A \times B \]
\[
	C = \left( 
		\begin{matrix}
			c_{00} & c_{0 1} & \ldots & c_{0(n-1)}\\
			c_{10} & c_{1 1} & \ldots & c_{1(n-1)}\\
			\vdots & \vdots & \ddots & \vdots\\
			c_{(n-1)0} & c_{(n-1)1} & \ldots & c_{(n-1)(n-1)}\\
		\end{matrix}
	\right), 
\] 

\par
где $(c_{ij}) = \sum\limits_{k=0}^{n-1}a_{ik}b_{kj}$   – результат скалярного произведения i-ой строки матрицы A и j-ого столбца матрицы B.

\par В алгоритме Фокса исходные матрицы делятся на блоки: каждой подзадаче даются свои подматрицы для подсчета результирующих 
подматриц.

\par
Предположим, что число подзадач равно 4, а n = 4.
Тогда блочное разбиение будет выглядеть следующим образом:

\par
\[ A_{00}= \left( 
	\begin{matrix}
		a_{00}  &  a_{01}\\
		a_{10}  &  a_{11}\\
	\end{matrix}
\right),
~A_{01}= \left( 
	\begin{matrix}
		a_{02}  &   a_{03}\\
		a_{12}  &   a_{13}\\
	\end{matrix}
\right)\] 
\[ A_{10}= \left( 
	\begin{matrix}
		a_{20}  &  a_{21}\\
		a_{30}  &  a_{31}\\
	\end{matrix}
\right),
~A_{11}= \left( 
	\begin{matrix}
		a_{22}  &  a_{23}\\
		a_{32}  &  a_{33}\\
	\end{matrix}
\right)\]

\par
\[B_{00}= \left(
	\begin{matrix}
		b_{00}  &  b_{01}\\
		b_{10}  &  b_{11}\\
	\end{matrix}
\right),
~B_{01}= \left(
	\begin{matrix}
		b_{02}  &   b_{03}\\
		b_{12}  &   b_{13}\\
	\end{matrix}
\right)\]
\[B_{10}= \left(
	\begin{matrix}
		b_{20}  &  b_{21}\\
		b_{30}  &  b_{31}\\
	\end{matrix}
\right),
~B_{11}= \left(
	\begin{matrix}
		b_{22}  &  b_{23}\\
		b_{32}  &  b_{33}\\
	\end{matrix}
\right)\] 

\par
А сама результирующая матрица будет выглядеть следующим образом:
\[C_{00} = A_{00} \times B_{00} + A_{01} \times B_{10}\]
\[C_{01} = A_{00} \times B_{01} + A_{01} \times B_{11}\]
\[C_{10} = A_{11} \times B_{10} + A_{10} \times B_{00}\]
\[C_{11} = A_{11} \times B_{11} + A_{10} \times B_{01}\]

\par
Алгоритм Фокса изначально разрабатывался для систем с распределенной памятью, и в них требовался обмен блоками между подзадачами.
Мы же реализуем данный алгоритм на потоках (т.е. в системе с общей памятью), а значит, обмен между подзадачами не нужен.
\newpage

% Программная реализация и схема распараллеливания
\section*{Программная реализация и схема распараллеливания}
\addcontentsline{toc}{section}{4. Программная реализация и схема распараллеливания}
В данном разделе мы рассмотрим две схемы распараллеливания описанного выше алгоритма, а также рассмотрим общие для обеих схем функции.
\par
В функции \lstinline$std::vector<double> getRandomMatrix(int size, time_t seed)$ создается 
\\
матрица с помощью генератора случайных чисел
\\
\lstinline$std::uniform_real_distribution<double>$ из библиотеки \lstinline$<random>$. 
\par 
Функция \lstinline$std::vector<double> sequentialFoxMultiplication(std::vector<double> $
\\
\lstinline$matrixA, std::vector<double> matrixB, int blockSize)$ производит 
\\ 
последовательное умножение матриц \lstinline$matrixA$ и \lstinline$matrixB$. 
\par
Для обеих реализаций используется функция 
\\ 
\lstinline$std::vector<double> parallelFoxMultiplication(std::vector<double> matrixA,$
\\
\lstinline$std::vector<double> matrixB)$. Особенности ее реализации рассмотрим ниже.
% Схема распараллеливания OpenMP
\subsection*{OpenMP}
\addcontentsline{toc}{subsection}{4.1. OpenMP}
\setcounter{subsection}{1}
До начала параллельной секции определим размеры сетки (как квадратный корень из количества потоков) и блоков матриц:
\begin{lstlisting}
	int gridSize = static_cast<int>(sqrt(threadCount));
  int blockSize = size / gridSize;
\end{lstlisting}
Затем идет параллельная секция, ее определяет директива:
\begin{lstlisting}
	#pragma omp parallel
\end{lstlisting}
Получаем номер текущего потока:
\begin{lstlisting}
	int threadNumber = omp_get_thread_num();
\end{lstlisting}
При помощи него определяем вспомогательные индексы для определения границ требуемых подматриц:
\begin{lstlisting}
	int ii = threadNumber / static_cast<int>(sqrt(threadCount));
  int jj = threadNumber %  static_cast<int>(sqrt(threadCount));
\end{lstlisting}
Затем запускаем цикл, подсчитывающий результирущую подматрицу:
\begin{lstlisting}
	for (int step = 0; step < gridSize; step++) {
    for (int i = ii * blockSize; i < (ii + 1) * blockSize; i++) {
      for (int j = jj * blockSize; j < (jj + 1) * blockSize; j++) {
        for (int k = step * blockSize; k < (step + 1) * blockSize; k++) {
          matrixC[i * size + j] += matrixA[i * size + k] *
          matrixB[k * size + j];
        }
      }
    }
  }
\end{lstlisting}
\newpage

% Схема распараллеливания TBB
\subsection*{TBB}
\addcontentsline{toc}{subsection}{4.2. TBB}
В данном случае все еще проще - воспользуемся классом \lstinline$blocked_range2d$.
Для начала создаем двухмерное пространство размером, как у результирущей матрицы:
\begin{lstlisting}
	tbb::parallel_for(
    tbb::blocked_range2d<int, int>(0, size, 0, size),
\end{lstlisting}
Затем создаем в нем еще одно двухмерное подпространство:
\begin{lstlisting}
	[&](tbb::blocked_range2d<int, int> r)
\end{lstlisting}
Внутри этого подпространства заводим цикл для подсчета результирущей подматрицы:
\begin{lstlisting}
	for (int j = r.rows().begin(); j != r.rows().end(); j++) {
		for (int i = r.cols().begin(); i != r.cols().end(); i++) {
			for (int k = 0; k < size; k++) {
				matrixC[j * size + i] += matrixA[j * size + k] *
				matrixB[k * size + i];
			}          
		}
  }
\end{lstlisting} 
\newpage

% Результаты экспериментов
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{5. Результаты экспериментов}
\begin{itemize}
\item Процессор: Intel Core i3-4130, 3400 MHz, физических ядер: 2, потоков: 4;
\item Оперативная память: 8192 МБ (DDR3), 1600 MHz;
\item ОС: Microsoft Windows 10 Home, версия 2004 сборка 19041.572.
\end{itemize}

\par Для оценки времени работы рассмотренных выше реализаций сгенерируем случайные матрицы размерами 100x100, 250x250, 500x500.
\par Результаты экспериментов представлены в Таблице 1.

\begin{table}[!h]
\caption{Результаты вычислительных экспериментов}
\renewcommand{\arraystretch}{1.8} 
\centering
\begin{tabular}{|l*{4}{|l}}
\hline
Размер матрицы & 100 & 250 & 500 \\
\hline
Последовательная реализация, с & 0.0031259 &  0.052267 & 0.458808 \\
\hline
OpenMP, с & 0.0010245 & 0.0151383 & 0.121995 \\
\hline
Ускорение OpenMP & 3.05 & 3.45 & 3.76 \\
\hline
TBB, с & 0.0013307 & 0.0224133 & 0.165033 \\
\hline
Ускорение TBB & 2.35 & 2.33 & 2.78 \\
\hline
\end{tabular}
\end{table}

\par Как можно видеть из Таблицы 1, параллельные версии быстрее последовательной. Однако версия OpenMP получилась производительнее,
т.к. в версии TBB использовался класс \lstinline$blocked_range2d$ - он, по сути, аналогичен двумерному массиву. 
Очевидно, что алгоритмическая сложность обхода двухмерного массива больше одномерного, так что для улучшения производительности можно 
было воспользоваться \lstinline$blocked_range<int>(0, size * size)$. В этом случае мы бы рассматривали одномерное пространство и 
накладные расходы на его создание были бы меньше.

\par Для оценки корректности реализованных версий алгоритма было проведено тестирование на платформе C++ Testing Framework.
\par Наборы тестов проверяли:
\begin{itemize}
	\item Корректность входных данных (матрицы должны быть одинакового размера)
	\item Равенство полученных при помощи метода Фокса матриц с матрицами, подсчитанными наивным способом. 
\end{itemize}

\par Все программные комплексы успешно прошли тестирование, что говорит о корректности наших параллельных реализаций.
\newpage

% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{6. Заключение}
\par Мы разработали последовательную и две параллельные версии метода перемножения матриц Фокса.
\par Нам удалось получить почти что четырехкратное ускорение для OpenMP версии (максимум 3.76), 
и почти что трехкратное ускорение для TBB (максимум 2.78). 
\par 
Путем тестирования мы выяснили, что наши реализации корректны - результаты
работы последовательных и параллельных версий одинаковы.
\newpage

% Список литературы
\addcontentsline{toc}{section}{7. Список литературы}
\begin{thebibliography}{1}
\bibitem{Gergel} Гергель В.П., Стронгин Р.Г. Высокопроизводительные вычисления для многоядерных многопроцессорных систем. 
— Н.Новгород: Изд-во ННГУ, 2010.
\bibitem{Antonov} Антонов А.С. Параллельное программирование с использованием технологии
OpenMP: Учебное пособие. — М.: Изд-во МГУ, 2009
\bibitem{Voevodin} Воеводин В.В., Воеводин Вл.В. Параллельные вычисления. — СПб.: БХВ-Петербург, 2002. 
\end{thebibliography}
\newpage

% Приложение
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
\par
Последовательная версия
\par
\lstinline$fox_mult.h$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#ifndef MODULES_TASK_1_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
	#define MODULES_TASK_1_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_

	#include <vector>
	#include <ctime>

	std::vector<double> getRandomMatrix(int size, time_t seed);
	std::vector<double> directMultiplication(std::vector<double> matrixA,
                    std::vector<double> matrixB);
	std::vector<double> foxMultiplication(std::vector<double> matrixA,
                    std::vector<double> matrixB, int blockSize);

	#endif  // MODULES_TASK_1_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
\end{lstlisting}
\par
\lstinline$fox_mult.cpp$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#include "../../../modules/task_1/gruzdeva_d_fox_mult/fox_mult.h"
	#include <random>
	#include <vector>

	std::vector<double> getRandomMatrix(int size, time_t seed) {
  	std::vector<double> matrix(size * size);
  	std::mt19937 gen((unsigned int)seed);
  	std::uniform_real_distribution<double> dis(-10, 10);

  	for (int i = 0; i < size * size; i++) {
    	matrix[i] = dis(gen);
  	}

  	return matrix;
	}

	std::vector<double> directMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB) {
  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrices sizes differ";
 	 }

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);

  	for (int i = 0; i < size; i++) {
    	for (int j = 0; j < size; j++) {
      	matrixC[i * size + j] = 0;
      	for (int k = 0; k < size; k++) {
        	matrixC[i * size + j] += matrixA[i * size + k]
        	* matrixB[k * size + j];
      	}
    	}
  	}

  	return matrixC;
	}

	std::vector<double> foxMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB, int blockSize) {
  	if (blockSize == 0) {
    	throw "Block size cannot be zero";
  	}

  	if (blockSize < 0) {
    	throw "Block size cannot negative";
  	}

  	if (matrixA.size() < (unsigned int)(blockSize * blockSize)) {
    	throw "Block size cannot be larger than size of original matrices";
  	}

  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrice's sizes differ";
  	}

  	if (static_cast<int>(sqrt(matrixA.size())) % blockSize != 0) {
    	throw "Cannot multiply matrices using this block size";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);
  	int blockCount = size / blockSize;

  	for (int i = 0; i < size * size; i++) {
    	matrixC[i] = 0;
  	}

  	for (int i = 0; i < size; i += blockCount) {
    	for (int j = 0; j < size; j += blockCount) {
      	for (int k = 0; k < size; k += blockCount) {
        	for (int ii = i; ii < std::min(size, i + blockCount); ii++) {
          	for (int jj = j; jj < std::min(size, j + blockCount); jj++) {
            	for (int kk = k; kk < std::min(size, k + blockCount); kk++) {
              	matrixC[ii * size + jj] += matrixA[ii * size + kk]
              	* matrixB[kk * size + jj];
            	}
          	}
        	}
      	}
    	}
  	}
  	return matrixC;
	}
\end{lstlisting}
\par
\lstinline$main.cpp$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#include <gtest/gtest.h>
	#include "../../../modules/task_1/gruzdeva_d_fox_mult/fox_mult.h"

	TEST(Matrix_Multiplication, CHECKING_DIRECT_MULTIPLICATION) {
  	  std::vector<double> A = {1, 2, 3, 4,
        	                     0, 1, 2, 3,
      	                       0, 0, 1, 2,
          	                   0, 0, 0, 1};

    	std::vector<double> B = {1, 2, 3, 4,
            	                 0, 1, 2, 3,
              	               0, 0, 1, 2,
                	             0, 0, 0, 1};

    	std::vector<double> C = {1, 4, 10, 20,
      	                       0, 1, 4, 10,
        	                     0, 0, 1, 4,
          	                   0, 0, 0, 1};

    	std::vector<double> C_Calculated = directMultiplication(A, B);

    	ASSERT_EQ(C_Calculated, C);
	}

	TEST(Matrix_Multiplication, CHECKING_FOX_MULTIPLICATION) {
  	  std::vector<double> A = {1, 2, 3, 4,
    	                         0, 1, 2, 3,
      	                       0, 0, 1, 2,
        	                     0, 0, 0, 1};

    	std::vector<double> B = {1, 2, 3, 4,
      	                       0, 1, 2, 3,
        	                     0, 0, 1, 2,
          	                   0, 0, 0, 1};

    	std::vector<double> C = {1, 4, 10, 20,
      	                       0, 1, 4, 10,
        	                     0, 0, 1, 4,
          	                   0, 0, 0, 1};

 		  std::vector<double> C_Calculated = foxMultiplication(A, B, 2);

    	ASSERT_EQ(C_Calculated, C);
	}

	TEST(Matrix_Multiplication, CHECKING_FOX_MULT_DIFFERENT_BLOCK_SIZE) {
  	  std::vector<double> A = {1, 2, 3, 4,
    	                         0, 1, 2, 3,
      	                       0, 0, 1, 2,
        	                     0, 0, 0, 1};

   	 std::vector<double> B = {1, 2, 3, 4,
    	                         0, 1, 2, 3,
      	                       0, 0, 1, 2,
        	                     0, 0, 0, 1};

    	std::vector<double> C = {1, 4, 10, 20,
      	                       0, 1, 4, 10,
        	                     0, 0, 1, 4,
          	                   0, 0, 0, 1};

 	 	  std::vector<double> C_Calculated = foxMultiplication(A, B, 4);

    	ASSERT_EQ(C_Calculated, C);
	}

	TEST(Matrix_Multiplication, EQUALITY_OF_DIRECT_AND_FOX_METHODS) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = foxMultiplication(A, B, 2);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Matrix_Multiplication, FOX_METHOD_WITH_DIFF_BLOCK_SIZE) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	std::vector<double> C1 = foxMultiplication(A, B, 4);

    	std::vector<double> C2 = foxMultiplication(A, B, 2);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Matrix_Multiplication, FOX_METHOD_WITH_DIFF_BLOCK_SIZE_LARGER) {
  	  std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

    	std::vector<double> C1 = foxMultiplication(A, B, 50);

    	std::vector<double> C2 = foxMultiplication(A, B, 10);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Matrix_Multiplication, THROW_DIFFERENT_MATRICES_SIZES) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(5, time(0) + 1);

    	ASSERT_ANY_THROW(foxMultiplication(A, B, 1));
	}

	TEST(Matrix_Multiplication, THROW_LARGE_BLOCK_SIZE) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	ASSERT_ANY_THROW(foxMultiplication(A, B, 17));
	}

	TEST(Matrix_Multiplication, THROW_NEGATIVE_BLOCK_SIZE) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	ASSERT_ANY_THROW(foxMultiplication(A, B, -1));
	}

	TEST(Matrix_Multiplication, THROW_WRONG_BLOCK_SIZE) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	ASSERT_ANY_THROW(foxMultiplication(A, B, 5));
	}

	TEST(Matrix_Multiplication, THROW_NULL_BLOCK_SIZE) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

   		std::vector<double> B = getRandomMatrix(4, time(0) + 1);

    	ASSERT_ANY_THROW(foxMultiplication(A, B, 0));
	}
\end{lstlisting}
\par
OpenMP
\par
\lstinline$fox_mult.h$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#ifndef MODULES_TASK_2_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
	#define MODULES_TASK_2_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_

	#include <omp.h>
	#include <vector>
	#include <ctime>

	std::vector<double> getRandomMatrix(int size, time_t seed);
	std::vector<double> directMultiplication(std::vector<double> matrixA,
	                    std::vector<double> matrixB);
	std::vector<double> sequentialFoxMultiplication(std::vector<double> matrixA,
 		                  std::vector<double> matrixB, int blockSize);
	std::vector<double> parallelFoxMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB, int threadCount);
	#endif  // MODULES_TASK_2_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
\end{lstlisting}
\par
\lstinline$fox_mult.cpp$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#include "../../../modules/task_2/gruzdeva_d_fox_mult/fox_mult.h"
	#include <omp.h>
	#include <random>
	#include <vector>

	std::vector<double> getRandomMatrix(int size, time_t seed) {
  	std::vector<double> matrix(size * size);
  	std::mt19937 gen((unsigned int)seed);
  	std::uniform_real_distribution<double> dis(-10, 10);

  	for (int i = 0; i < size * size; i++) {
    	matrix[i] = dis(gen);
  	}

  	return matrix;
	}

	std::vector<double> directMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB) {
  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrices sizes differ";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);

  	for (int i = 0; i < size; i++) {
    	for (int j = 0; j < size; j++) {
      	matrixC[i * size + j] = 0;
      	for (int k = 0; k < size; k++) {
        	matrixC[i * size + j] += matrixA[i * size + k]
        	* matrixB[k * size + j];
      	}
    	}
  	}

  	return matrixC;
	}

	std::vector<double> sequentialFoxMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB, int blockSize) {
  	if (blockSize == 0) {
    	throw "Block size cannot be zero";
  	}

  	if (blockSize < 0) {
    	throw "Block size cannot be negative";
  	}

  	if (matrixA.size() < (unsigned int)(blockSize * blockSize)) {
    	throw "Block size cannot be larger than size of original matrices";
  	}

  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrice's sizes differ";
  	}

  	if (static_cast<int>(sqrt(matrixA.size())) % blockSize != 0) {
    	throw "Cannot multiply matrices using this block size";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);
  	int blockCount = size / blockSize;

  	for (int i = 0; i < size * size; i++) {
    	matrixC[i] = 0;
  	}

  	for (int i = 0; i < size; i += blockCount) {
    	for (int j = 0; j < size; j += blockCount) {
      	for (int k = 0; k < size; k += blockCount) {
        	for (int ii = i; ii < std::min(size, i + blockCount); ii++) {
          	for (int jj = j; jj < std::min(size, j + blockCount); jj++) {
            	for (int kk = k; kk < std::min(size, k + blockCount); kk++) {
              	matrixC[ii * size + jj] += matrixA[ii * size + kk]
              	* matrixB[kk * size + jj];
            	}
          	}
        	}
      	}
    	}
  	}
  	return matrixC;
	}

	std::vector<double> parallelFoxMultiplication(std::vector<double> matrixA,
  	                  std::vector<double> matrixB, int threadCount) {
  	if (threadCount == 0) {
    	throw "Number of threads cannot be zero";
  	}

  	if (threadCount < 0) {
    	throw "Number of threads cannot be negative";
  	}

  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrice's sizes differ";
  	}

  	if (matrixA.size() %  static_cast<int>(sqrt(threadCount)) != 0) {
    	throw "Cannot distribute data between threads";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	int gridSize = static_cast<int>(sqrt(threadCount));
  	int blockSize = size / gridSize;
  	std::vector<double> matrixC(size * size);

  	#pragma omp parallel
  	{
    	int threadNumber = omp_get_thread_num();
    	int ii = threadNumber / static_cast<int>(sqrt(threadCount));
    	int jj = threadNumber %  static_cast<int>(sqrt(threadCount));

	    for (int step = 0; step < gridSize; step++) {
  	    for (int i = ii * blockSize; i < (ii + 1) * blockSize; i++) {
    	    for (int j = jj * blockSize; j < (jj + 1) * blockSize; j++) {
      	    for (int k = step * blockSize; k < (step + 1) * blockSize; k++) {
        	    matrixC[i * size + j] += matrixA[i * size + k] *
          	  matrixB[k * size + j];
          	}
        	}
      	}
    	}
  	}

  	return matrixC;
	}
\end{lstlisting}
\par
\lstinline$main.cpp$
\begin{lstlisting}
	#include <gtest/gtest.h>

	#include <omp.h>
	#include <random>
	#include <vector>

	#include "../../../modules/task_2/gruzdeva_d_fox_mult/fox_mult.h"

	TEST(Fox_Multiplication_OMP, DIRECT_AND_FOX_1) {
  	  std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

  	  std::vector<double> C1 = directMultiplication(A, B);

  	  std::vector<double> C2 = parallelFoxMultiplication(A, B, 4);

  	  ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_OMP, DIRECT_AND_FOX_2) {
  	  std::vector<double> A = getRandomMatrix(250, time(0));

  	  std::vector<double> B = getRandomMatrix(250, time(0) + 1);

  	  std::vector<double> C1 = directMultiplication(A, B);

  	  std::vector<double> C2 = parallelFoxMultiplication(A, B, 4);

  	  ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_OMP, SEQ_FOX_AND_PAR_FOX_1) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);
    	double t1 = omp_get_wtime();
    	std::vector<double> C1 = sequentialFoxMultiplication(A, B, 4);
    	double t2 = omp_get_wtime();
    	std::cout << "Direct: " << t2-t1 << "\n";
    	t1 = omp_get_wtime();
    	std::vector<double> C2 = parallelFoxMultiplication(A, B, 4);
    	t2 = omp_get_wtime();
  	  std::cout << "OMP: " << t2-t1 << "\n";

  	  ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_OMP, SEQ_FOX_AND_PAR_FOX_2) {
    	std::vector<double> A = getRandomMatrix(250, time(0));

  	  std::vector<double> B = getRandomMatrix(250, time(0) + 1);
  	  double t1 = omp_get_wtime();
  	  std::vector<double> C1 = sequentialFoxMultiplication(A, B, 2);
  	  double t2 = omp_get_wtime();
  	  std::cout << "Direct: " << t2-t1 << "\n";
  	  t1 = omp_get_wtime();
  	  std::vector<double> C2 = parallelFoxMultiplication(A, B, 4);
  	  t2 = omp_get_wtime();
  	  std::cout << "OMP: " << t2-t1 << "\n";

  	  ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_OMP, DIRECT_AND_FOX_4) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = parallelFoxMultiplication(A, B, 4);

  	  ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_OMP, THROW_DIFFERENT_MATRICES_SIZES) {
    	std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(5, time(0) + 1);

  	  ASSERT_ANY_THROW(parallelFoxMultiplication(A, B, 4));
	}

	TEST(Fox_Multiplication_OMP, THROW_NEGATIVE_THREAD) {
    	std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

  	  ASSERT_ANY_THROW(parallelFoxMultiplication(A, B, -2));
	}

	TEST(Fox_Multiplication_OMP, THROW_WRONG_THREAD_NUMBER) {
    	std::vector<double> A = getRandomMatrix(5, time(0));

    	std::vector<double> B = getRandomMatrix(5, time(0) + 1);

  	  ASSERT_ANY_THROW(parallelFoxMultiplication(A, B, 8));
	}

	TEST(Fox_Multiplication_OMP, THROW_NULL_THREAD_NUMBER) {
    	std::vector<double> A = getRandomMatrix(4, time(0));

    	std::vector<double> B = getRandomMatrix(4, time(0) + 1);

  	  ASSERT_ANY_THROW(parallelFoxMultiplication(A, B, 0));
	}

\end{lstlisting}
\par
TBB
\par
\lstinline$fox_mult.h$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#ifndef MODULES_TASK_3_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
	#define MODULES_TASK_3_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_

	#include <algorithm>
	#include <vector>
	#include <ctime>

	std::vector<double> getRandomMatrix(int size, time_t seed);
	std::vector<double> directMultiplication(std::vector<double> matrixA,
                    std::vector<double> matrixB);
	std::vector<double> sequentialFoxMultiplication(std::vector<double> matrixA,
                    std::vector<double> matrixB, int blockSize);
	std::vector<double> parallelFoxMultiplication(std::vector<double> matrixA,
                    std::vector<double> matrixB);

	#endif  // MODULES_TASK_3_GRUZDEVA_D_FOX_MULT_FOX_MULT_H_
\end{lstlisting}
\par
\lstinline$fox_mult.cpp$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#define NOMINMAX

	#include "../../../modules/task_3/gruzdeva_d_fox_mult/fox_mult.h"
	#include <tbb/parallel_for.h>
	#include <tbb/blocked_range2d.h>
	#include <random>
	#include <algorithm>
	#include <vector>

	std::vector<double> getRandomMatrix(int size, time_t seed) {
  	std::vector<double> matrix(size * size);
  	std::mt19937 gen((unsigned int)seed);
  	std::uniform_real_distribution<double> dis(-10, 10);

  	for (int i = 0; i < size * size; i++) {
    	matrix[i] = dis(gen);
  	}

  	return matrix;
	}

	std::vector<double> directMultiplication(std::vector<double> matrixA,
    	                std::vector<double> matrixB) {
  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrices sizes differ";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);

  	for (int i = 0; i < size; i++) {
    	for (int j = 0; j < size; j++) {
      	matrixC[i * size + j] = 0;
      	for (int k = 0; k < size; k++) {
        	matrixC[i * size + j] += matrixA[i * size + k]
        	* matrixB[k * size + j];
      	}
    	}
  	}

  	return matrixC;
	}

	std::vector<double> sequentialFoxMultiplication(std::vector<double> matrixA,
    	                std::vector<double> matrixB, int blockSize) {
  	if (blockSize == 0) {
    	throw "Block size cannot be zero";
  	}

  	if (blockSize < 0) {
    	throw "Block size cannot be negative";
  	}

  	if (matrixA.size() < (unsigned int)(blockSize * blockSize)) {
    	throw "Block size cannot be larger than size of original matrices";
  	}

  	if (matrixA.size() != matrixB.size()) {
    	throw "Matrice's sizes differ";
  	}

  	if (static_cast<int>(sqrt(matrixA.size())) % blockSize != 0) {
    	throw "Cannot multiply matrices using this block size";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);
  	int blockCount = size / blockSize;

  	for (int i = 0; i < size * size; i++) {
    	matrixC[i] = 0;
  	}

  	for (int i = 0; i < size; i += blockCount) {
    	for (int j = 0; j < size; j += blockCount) {
      	for (int k = 0; k < size; k += blockCount) {
        	for (int ii = i; ii < std::min(size, i + blockCount); ii++) {
          	for (int jj = j; jj < std::min(size, j + blockCount); jj++) {
            	for (int kk = k; kk < std::min(size, k + blockCount); kk++) {
              	matrixC[ii * size + jj] += matrixA[ii * size + kk]
              	* matrixB[kk * size + jj];
            	}
          	}
        	}
      	}
    	}
  	}
  	return matrixC;
	}

	std::vector<double> parallelFoxMultiplication(std::vector<double> matrixA,
    	                std::vector<double> matrixB) {
  	if (matrixA.size() != matrixB.size()) {
  	  throw "Matrice's sizes differ";
  	}

  	int size = static_cast<int>(sqrt(matrixA.size()));
  	std::vector<double> matrixC(size * size);

  	tbb::parallel_for(
    	tbb::blocked_range2d<int, int>(0, size, 0, size),
    	[&](tbb::blocked_range2d<int, int> r) {
        	for (int j = r.rows().begin(); j != r.rows().end(); j++) {
                	for (int i = r.cols().begin(); i != r.cols().end(); i++) {
                	    for (int k = 0; k < size; k++) {
              	          matrixC[j * size + i] += matrixA[j * size + k] *
            	            matrixB[k * size + i];
          	          }
        	        }
      	      }
    	});
  	return matrixC;
	}
\end{lstlisting}
\par
\lstinline$main.cpp$
\begin{lstlisting}
	// Copyright 2021 Gruzdeva Diana

	#include <gtest/gtest.h>

	#include <tbb/tick_count.h>
	#include <random>
	#include <vector>
	#include <iostream>

	#include "../../../modules/task_3/gruzdeva_d_fox_mult/fox_mult.h"

	TEST(Fox_Multiplication_TBB, DIRECT_AND_FOX_1) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = sequentialFoxMultiplication(A, B, 4);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, DIRECT_AND_FOX_2) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = sequentialFoxMultiplication(A, B, 25);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, DIRECT_AND_PARALL_FOX_1) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = parallelFoxMultiplication(A, B);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, DIRECT_AND_PARALL_FOX_2) {
    	std::vector<double> A = getRandomMatrix(250, time(0));

    	std::vector<double> B = getRandomMatrix(250, time(0) + 1);

    	std::vector<double> C1 = directMultiplication(A, B);

    	std::vector<double> C2 = parallelFoxMultiplication(A, B);

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, SEQ_FOX_AND_PAR_FOX_1) {
    	std::vector<double> A = getRandomMatrix(100, time(0));

    	std::vector<double> B = getRandomMatrix(100, time(0) + 1);
    	tbb::tick_count t1 = tbb::tick_count::now();
    	std::vector<double> C1 = sequentialFoxMultiplication(A, B, 25);
    	tbb::tick_count t2 = tbb::tick_count::now();
    	std::cout << "Direct: " << (t2-t1).seconds() << "\n";
    	t1 = tbb::tick_count::now();
    	std::vector<double> C2 = parallelFoxMultiplication(A, B);
    	t2 = tbb::tick_count::now();
    	std::cout << "TBB: " << (t2-t1).seconds()  << "\n";

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, SEQ_FOX_AND_PAR_FOX_2) {
    	std::vector<double> A = getRandomMatrix(250, time(0));

    	std::vector<double> B = getRandomMatrix(250, time(0) + 1);
    	tbb::tick_count t1 = tbb::tick_count::now();
    	std::vector<double> C1 = sequentialFoxMultiplication(A, B, 2);
    	tbb::tick_count t2 = tbb::tick_count::now();
    	std::cout << "Direct: " << (t2-t1).seconds() << "\n";
    	t1 = tbb::tick_count::now();
    	std::vector<double> C2 = parallelFoxMultiplication(A, B);
    	t2 = tbb::tick_count::now();
    	std::cout << "TBB: " << (t2-t1).seconds()  << "\n";

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, SEQ_FOX_AND_PAR_FOX_3) {
    	std::vector<double> A = getRandomMatrix(500, time(0));

    	std::vector<double> B = getRandomMatrix(500, time(0) + 1);
    	tbb::tick_count t1 = tbb::tick_count::now();
    	std::vector<double> C1 = sequentialFoxMultiplication(A, B, 4);
    	tbb::tick_count t2 = tbb::tick_count::now();
    	std::cout << "Direct: " << (t2-t1).seconds()  << "\n";
    	t1 = tbb::tick_count::now();
    	std::vector<double> C2 = parallelFoxMultiplication(A, B);
    	t2 = tbb::tick_count::now();
    	std::cout << "TBB: " << (t2-t1).seconds() << "\n";

    	ASSERT_EQ(C1, C2);
	}

	TEST(Fox_Multiplication_TBB, THROW_DIFFERENT_MATRICES_SIZES) {
  	  std::vector<double> A = getRandomMatrix(4, time(0));

  	  std::vector<double> B = getRandomMatrix(5, time(0) + 1);

  	  ASSERT_ANY_THROW(parallelFoxMultiplication(A, B));
}
\end{lstlisting}

\end{document}