\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{amsmath}

\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\lstset{language=C++,
		basicstyle=\footnotesize,
		keywordstyle=\color{blue}\ttfamily,
		stringstyle=\color{red}\ttfamily,
		commentstyle=\color{green}\ttfamily,
		morecomment=[l][\color{magenta}]{\#}, 
		tabsize=4,
		breaklines=true,
  		breakatwhitespace=true,
  		title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large«Решение систем линейных уравнений методом сопряженных градиентов»} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнила:} \\ студентка группы 381808-2 \\ Хисматулина К.Ф. \\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В. \\
}
\vspace{\fill}

\begin{center} Нижний Новгород \\ 2021 \end{center}

\end{titlepage}

\setcounter{page}{2}

% Содержание
\tableofcontents
\newpage

% Введение
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
Метод сопряженных градиентов – один из наиболее известных итерационных методов решения систем линейных уравнений. Он может быть применен для решения системы линейных уравнений с симметричной, положительноопределенной матрицей.
\newpage

% Постановка задачи
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
Целью данной лабораторной работы является разработка последовательной и параллельной версий решения СЛАУ методом сопряжённых градиентов. 
\par Под задачей решения системы линейных уравнений для заданных матрицы А и вектора b понимается нахождение значения вектора неизвестных x, при котором выполняются все уравнения системы.
\par Необходимо реализовать последовательную и параллельную версию программы. Для реализации параллельной версии необходимо использовать средства OMP, TBB. Для проверки корректности работы программы необходимо использовать GTest.
\newpage

% Описание алгоритма
\section*{Описание алгоритма}
\addcontentsline{toc}{section}{Описание алгоритма}
После выполнения n итераций метода сопряженных градиентов(n есть порядок решаемой системы линейных уравнений), очередное приближение Xn совпадает с точным решением. Итерация метода сопряженных градиентов состоит в вычислении очередного приближения к точному решению.
\par Описание алгоритма:
\begin{itemize}
\item Вычисление градиента
\item Вычисление вектора направления
\item Вычисление величины смещения по заданному направлению
\item Вычисление нового приближения
\end{itemize}

\newpage

% Описание схемы распараллеливания
\section*{Описание схемы распараллеливания}
\addcontentsline{toc}{section}{Описание схемы распараллеливания}

Выполнение итераций метода осуществляется последовательно, следовательно наиболее целесообразный подход состоит в распараллеливании вычислений, реализуемых в ходе выполнения отдельных итераций. Основные вычисления, выполняемые в соответствии с методом, состоят в перемножении матрицы на вектора. Дополнительные вычисления, имеющие меньший порядок сложности, представляют собой различные операции обработки векторов(скалярное произведение, сложение и вычитание, умножение на скаляр).
\par Для достижения данного результата в OpenMP существует деректива препроцессора $pragma omp parallel for reduction$, а в TBB $tbb::parallel_reduce$.
\newpage

% Описание программной реализации
\section*{Описание программной реализации}
\addcontentsline{toc}{section}{Описание программной реализации}\
Входными параметрами всех реализаций алгоритма являются:
\begin{itemize}
\item const std::vector<double>matrix - положительно определённая симметричная матрица
\item const std::vector<double> vector - вектор
\item int size, int proc - размер матрицы, кол-во процессов
\end{itemize}

\par Используемые методы:
\par multVVOMP(std::vector<double> A, std::vector<double> B) - перемножение векторов
\par multMVOMP(std::vector<double> m, std::vector<double> v) - перемножение матрицы на вектор
\par gradient(const std::vector<double> matrix, const std::vector<double> vector, int size, int proc) - сам процесс решения СЛАУ

\newpage

% Результаты экспериментов
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{Результаты экспериментов}
Вычислительные эксперименты проводились на оборудовании со следующей аппаратной конфигурацией:

\begin{itemize}
\item Процессор: Intel(R) Core(TM) i5-6800 CPU @ 2.1GHz, ядер: 4
\item Оперативная память: 8 ГБ DDR4;
\item ОС: Microsoft Windows 10 Pro
\end{itemize}

\par Тестирование производилось при $N=100$ млн., $f=sin(x_1)+sin(x_2)+sin(x_3)$
\\

\begin{table}[!h]
\begin{center}
\begin{tabular}{lllllll}
Реализация & Время & Ускорение   \\
SEQ        & 3.4 & 1           \\
OMP        & 2.9 & 1.17      \\

\end{tabular}
\end{center}
\caption{Результаты вычислительных экспериментов}
\centering
\end{table}

\par Из полученных результатов видно, что удалось получить значительное ускорение в параллельных реализациях можно, но для этого надо иметь мозг. Исходя из этого можно сделать вывод, что данный алгоритм в принципе  хорошо поддается распараллеливанию.
\newpage

% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
В результате лабораторной работы были разработаны последовательная и параллельная реализация решения СЛАУ методом сопряжённых градиентов.
\par Была разработана последовательная версия алгоритма,  и на ее основе были полученны параллельные реализации с использованием OpenMP и TBB.
\par Из результатов вычислительных экспериментов видно, что параллельные реализации алгоритма могут являться эффективными, но не в моём случае.
\newpage

% Литература
\begin{thebibliography}{1}
\addcontentsline{toc}{section}{Литература}
\bibitem{} «Параллельное программирование на OpenMP»
\bibitem{Sidnev} Сиднев А.А., Мееров И.Б., Сысоев А.В. «Разработка параллельных программ в системах с общей памятью с использованием библиотеки Intel Threading Building Blocks (TBB)».
\bibitem{} «Параллельное программирование. С++. Thread Support Library. Atomic Operations Library.»
\end{thebibliography}
\newpage

% Приложение
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
В данном разделе находится реализация методов последовательной и параллельной реализции алгоритма
\begin{lstlisting}
// Copyright 2021 Khismatulina Karina
#include <vector>
#include <cassert>
#include <random>
#include "../../../modules/task_1/khismatulina_k_gradient/seq.h"

std::vector<double> getRandomVector(int size) {
    // assert(size > 0);
    if (size < 0) throw("size ouhgt to be > 0");
    std::random_device rd;
    std::mt19937 mersenne(rd());
    std::vector<double> vec(size, 1);
    for (int i = 0; i < size; ++i) {
        vec[i] = mersenne() * mersenne() % 7;
    }
    return vec;
}

std::vector<double> getRandomMatrix(int size) {
    assert(size > 0);
    std::random_device rd;
    std::mt19937 mersenne(rd());
    std::vector<double> matrix(size, 1);
    for (int i = 0; i < size; ++i) {
        for (int j = 0; j < size; ++j) {
            matrix[i * size + j] = matrix[j * size + i] = mersenne() * mersenne() % 7;
        }
    }
    return matrix;
}

double multVV(std::vector<double> A, std::vector<double> B) {
    assert(A.size() == B.size());
    double result = 0;
    for (size_t i = 0; i < A.size(); ++i) {
        result += A[i] * B[i];
    }
    return result;
}

std::vector<double> multMV(std::vector<double> m, std::vector<double> v) {
    assert(m.size() > 0 && v.size() > 0);
    assert(m.size() % v.size() == 0);
    std::vector<double> result(m.size() / v.size());
    for (size_t i = 0; i < result.size(); ++i) {
        for (size_t j = 0; j < v.size(); ++j) {
            result[i] += m[i * v.size() + j] * v[j];
        }
    }
    return result;
}

std::vector<double> gradientSeq(const std::vector<double>& matrix, const std::vector<double>& vector, int size) {
    assert(size > 0);
    int iters = 0;
    double eps = 0.1, beta = 0.0, alpha = 0.0, check = 0.0;
    std::vector<double> res(size, 1);
    std::vector<double> Ah = multMV(matrix, res);
    std::vector<double> discrepancyCurrent(size), discrepancyNext(size);
    for (int i = 0; i < size; ++i) {
        discrepancyCurrent[i] = vector[i] - Ah[i];
    }
    std::vector<double> h(discrepancyCurrent);
    do {
        iters++;
        Ah = multMV(matrix, h);
        alpha = multVV(discrepancyCurrent, discrepancyNext) / multVV(h, Ah);
        for (int i = 0; i < size; ++i) {
            res[i] += alpha * h[i];
            discrepancyNext[i] = discrepancyCurrent[i] - alpha * Ah[i];
        }
        beta = multVV(discrepancyNext, discrepancyNext) / multVV(discrepancyCurrent, discrepancyCurrent);
        check = sqrt(multVV(discrepancyNext, discrepancyNext));
        for (int k = 0; k < size; ++k) {
            h[k] = discrepancyNext[k] + beta * h[k];
        }
        std::vector<double> swap = discrepancyNext;
        discrepancyNext = discrepancyCurrent;
        discrepancyCurrent = swap;
    } while ((check > eps) && (iters <= size));
    return res;
}

\end{lstlisting}

\begin{lstlisting}
// Copyright 2021 Khismatulina Karina
#include <omp.h>
#include <vector>
#include <cassert>
#include <random>
#include <iostream>
#include "../../../modules/task_2/khismatulina_k_gradient/omp.h"

double MyAbs(double x) {
    if (x < 0) return -x;
    return x;
}

std::vector<double> getRandomVectorOMP(int size) {
    if (size < 0) throw("size ouhgt to be > 0");
    std::random_device rd;
    std::mt19937 mersenne(rd());
    std::vector<double> vec(size, 1);
    for (int i = 0; i < size; ++i) {
        vec[i] = mersenne() * mersenne() % 7;
    }
    return vec;
}

std::vector<double> getRandomMatrixOMP(int size) {
    assert(size > 0);
    std::random_device rd;
    std::mt19937 mersenne(rd());
    std::vector<double> matrix(size*size, 1);
    for (int i = 0; i < size; ++i) {
        for (int j = 0; j < size; ++j) {
            matrix[i * size + j] = matrix[j * size + i] = mersenne() * mersenne() % 7;
        }
    }
    return matrix;
}

double multVVOMP(std::vector<double> A, std::vector<double> B) {
    assert(A.size() == B.size());
    double result = 0;
    int size_A = A.size();
#pragma omp parallel for reduction(+:result)
    for (int i = 0; i < size_A; ++i) {
        result += A[i] * B[i];
    }
    return result;
}

std::vector<double> multMVOMP(std::vector<double> m, std::vector<double> v) {
    assert(m.size() > 0 && v.size() > 0);
    assert(m.size() % v.size() == 0);
    std::vector<double> result(m.size() / v.size());
    int size_r = result.size();
#pragma omp parallel for
    for (int i = 0; i < size_r; ++i) {
        for (int j = 0; j < size_r; ++j) {
            result[i] += m[i * v.size() + j] * v[j];
        }
    }
    return result;
}

bool gradientParOMP(const std::vector<double>& matrix, const std::vector<double>& vector, int size, int proc) {
    assert(size > 0);
    int iters = 0;
    double eps = 0.1, beta = 0.0, alpha = 0.0, check = 0.0;
    int i, k = 0;
    std::vector<double> res(size, 1);
    std::vector<double> Ah = multMVOMP(matrix, res);
    std::vector<double> discrepancyCurrent(size), discrepancyNext(size);
#pragma omp parallel for private(i)
    for (i = 0; i < size; ++i) {
        discrepancyCurrent[i] = vector[i] - Ah[i];
    }
    std::vector<double> h(discrepancyCurrent);
    do {
        iters++;
        Ah = multMVOMP(matrix, h);
        alpha = multVVOMP(discrepancyCurrent, discrepancyNext) / multVVOMP(h, Ah);
#pragma omp parallel for private(i)
        for (i = 0; i < size; ++i) {
            res[i] += alpha * h[i];
            discrepancyNext[i] = discrepancyCurrent[i] - alpha * Ah[i];
        }
        beta = multVVOMP(discrepancyNext, discrepancyNext) / multVVOMP(discrepancyCurrent, discrepancyCurrent);
        check = sqrt(multVVOMP(discrepancyNext, discrepancyNext));
#pragma omp parallel for private(k)
        for (k = 0; k < size; ++k) {
            h[k] = discrepancyNext[k] + beta * h[k];
        }
        std::vector<double> swap = discrepancyNext;
        discrepancyNext = discrepancyCurrent;
        discrepancyCurrent = swap;
    } while ((check > eps) && (iters <= size));

    std::vector<double> A_check(size);
    int correct = 0;
    int F = size / 10;
    if (size / 10 == 0) {
        F = 1;
    }
    double fail = 0.1 * F;
    for (int i = 0; i < size; ++i) {
        A_check[i] = 0;
        for (int j = 0; j < size; ++j) {
            A_check[i] += matrix[i * size + j] * res[j];
        }
        if ((MyAbs(A_check[i]) > MyAbs(vector[i]) && (MyAbs(A_check[i]) - MyAbs(vector[i]) > fail)) ||
            ((MyAbs(A_check[i]) <= MyAbs(vector[i])) && (MyAbs(vector[i]) - MyAbs(A_check[i]) > fail))) {
            correct = 1;
            break;
        }
    }
    return correct;
}

\end{lstlisting}

\begin{lstlisting}

\end{lstlisting}

\end{document}